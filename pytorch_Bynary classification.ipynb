{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027818</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Prediction is done by using binary classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027818  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12 Class_att  \\\n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal   \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal   \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal   \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal   \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal   \n",
       "\n",
       "                                         Unnamed: 13  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  Prediction is done by using binary classificat...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset_spine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Col1', 'Col2', 'Col3', 'Col4', 'Col5', 'Col6', 'Col7', 'Col8', 'Col9',\n",
       "       'Col10', 'Col11', 'Col12', 'Class_att', 'Unnamed: 13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 13', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115042cbbc8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Class_att', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class_att'] = df['Class_att'].astype('category')\n",
    "encode_map = {\n",
    "    'Abnormal': 1,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "df['Class_att'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that we did not use the Sigmoid activation in our final layer during training. That’s because, we use the \n",
    "#nn.BCEWithLogitsLoss() loss function which automatically applies the the Sigmoid activation.\n",
    "\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(12, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "###################### OUTPUT ######################\n",
    "cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=12, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.69858 | Acc: 54.750\n",
      "Epoch 002: | Loss: 0.56625 | Acc: 73.000\n",
      "Epoch 003: | Loss: 0.51259 | Acc: 78.000\n",
      "Epoch 004: | Loss: 0.46322 | Acc: 82.500\n",
      "Epoch 005: | Loss: 0.42655 | Acc: 85.000\n",
      "Epoch 006: | Loss: 0.44889 | Acc: 81.250\n",
      "Epoch 007: | Loss: 0.41835 | Acc: 82.000\n",
      "Epoch 008: | Loss: 0.44717 | Acc: 81.000\n",
      "Epoch 009: | Loss: 0.41636 | Acc: 81.000\n",
      "Epoch 010: | Loss: 0.41555 | Acc: 83.500\n",
      "Epoch 011: | Loss: 0.42582 | Acc: 84.000\n",
      "Epoch 012: | Loss: 0.35678 | Acc: 85.250\n",
      "Epoch 013: | Loss: 0.33267 | Acc: 87.250\n",
      "Epoch 014: | Loss: 0.31181 | Acc: 92.250\n",
      "Epoch 015: | Loss: 0.31352 | Acc: 85.750\n",
      "Epoch 016: | Loss: 0.28865 | Acc: 92.250\n",
      "Epoch 017: | Loss: 0.28409 | Acc: 91.500\n",
      "Epoch 018: | Loss: 0.26664 | Acc: 93.750\n",
      "Epoch 019: | Loss: 0.28886 | Acc: 87.500\n",
      "Epoch 020: | Loss: 0.28618 | Acc: 88.000\n",
      "Epoch 021: | Loss: 0.21802 | Acc: 93.250\n",
      "Epoch 022: | Loss: 0.21884 | Acc: 93.500\n",
      "Epoch 023: | Loss: 0.22373 | Acc: 92.750\n",
      "Epoch 024: | Loss: 0.27108 | Acc: 90.750\n",
      "Epoch 025: | Loss: 0.25554 | Acc: 87.000\n",
      "Epoch 026: | Loss: 0.24115 | Acc: 92.000\n",
      "Epoch 027: | Loss: 0.22268 | Acc: 93.000\n",
      "Epoch 028: | Loss: 0.21827 | Acc: 93.500\n",
      "Epoch 029: | Loss: 0.18995 | Acc: 93.500\n",
      "Epoch 030: | Loss: 0.17897 | Acc: 95.000\n",
      "Epoch 031: | Loss: 0.17896 | Acc: 96.500\n",
      "Epoch 032: | Loss: 0.17082 | Acc: 94.000\n",
      "Epoch 033: | Loss: 0.21935 | Acc: 94.750\n",
      "Epoch 034: | Loss: 0.16834 | Acc: 93.500\n",
      "Epoch 035: | Loss: 0.13595 | Acc: 96.500\n",
      "Epoch 036: | Loss: 0.18827 | Acc: 92.250\n",
      "Epoch 037: | Loss: 0.14067 | Acc: 95.000\n",
      "Epoch 038: | Loss: 0.15300 | Acc: 92.500\n",
      "Epoch 039: | Loss: 0.16408 | Acc: 93.250\n",
      "Epoch 040: | Loss: 0.15370 | Acc: 95.000\n",
      "Epoch 041: | Loss: 0.16247 | Acc: 94.750\n",
      "Epoch 042: | Loss: 0.14563 | Acc: 95.000\n",
      "Epoch 043: | Loss: 0.10682 | Acc: 97.750\n",
      "Epoch 044: | Loss: 0.10628 | Acc: 99.000\n",
      "Epoch 045: | Loss: 0.10549 | Acc: 97.250\n",
      "Epoch 046: | Loss: 0.10695 | Acc: 98.750\n",
      "Epoch 047: | Loss: 0.09094 | Acc: 98.750\n",
      "Epoch 048: | Loss: 0.08381 | Acc: 98.750\n",
      "Epoch 049: | Loss: 0.17141 | Acc: 91.750\n",
      "Epoch 050: | Loss: 0.11375 | Acc: 95.000\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26,  5],\n",
       "       [14, 58]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73        31\n",
      "           1       0.92      0.81      0.86        72\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.79      0.82      0.80       103\n",
      "weighted avg       0.84      0.82      0.82       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
